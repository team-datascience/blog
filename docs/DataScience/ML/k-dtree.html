<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>k-dtree · Team Data Scientists</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="A K-D Tree(also called as K-Dimensional Tree) is a binary search tree where data in each node is a K-Dimensional point in space. ... A non-leaf node in K-D tree divides the space into two parts, called as half-spaces."/><meta name="docsearch:language" content="en"/><meta property="og:title" content="k-dtree · Team Data Scientists"/><meta property="og:type" content="website"/><meta property="og:url" content="https://team-datascience.github.io/blog/"/><meta property="og:description" content="A K-D Tree(also called as K-Dimensional Tree) is a binary search tree where data in each node is a K-Dimensional point in space. ... A non-leaf node in K-D tree divides the space into two parts, called as half-spaces."/><meta property="og:image" content="https://team-datascience.github.io/blog/img/undraw_online.svg"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://team-datascience.github.io/blog/img/undraw_tweetstorm.svg"/><link rel="shortcut icon" href="/blog/img/I_love_AI.png"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><link rel="alternate" type="application/atom+xml" href="https://team-datascience.github.io/blog/blog/atom.xml" title="Team Data Scientists Blog ATOM Feed"/><link rel="alternate" type="application/rss+xml" href="https://team-datascience.github.io/blog/blog/feed.xml" title="Team Data Scientists Blog RSS Feed"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script src="https://unpkg.com/vanilla-back-to-top@7.1.14/dist/vanilla-back-to-top.min.js"></script><script>
        document.addEventListener('DOMContentLoaded', function() {
          addBackToTop(
            {"zIndex":100}
          )
        });
        </script><script src="/blog/js/scrollSpy.js"></script><link rel="stylesheet" href="/blog/css/main.css"/><script src="/blog/js/codetabs.js"></script></head><body class="sideNavVisible separateOnPageNav"><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/blog/"><img class="logo" src="/blog/img/I_love_AI.png" alt="Team Data Scientists"/><h2 class="headerTitleWithLogo">Team Data Scientists</h2></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/blog/docs/Profiles1/ProfilesIntro" target="_self">Profiles</a></li><li class=""><a href="/blog/docs/DataScientistProfiles/ProfileInfo" target="_self">Data Scientist Profiles</a></li><li class=""><a href="/blog/docs/doc4" target="_self">Technical</a></li><li class=""><a href="/blog/docs/alogorithms/alogorithmsIntro" target="_self">alogorithms</a></li><li class=""><a href="/blog/docs/tools/tools-overview" target="_self">Tools</a></li><li class="siteNavGroupActive"><a href="/blog/docs/DataScience/datascience" target="_self">DataScience</a></li><li class=""><a href="/blog/help" target="_self">Help</a></li><li class=""><a href="/blog/blog/" target="_self">Blog</a></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="docsNavContainer" id="docsNav"><nav class="toc"><div class="toggleNav"><section class="navWrapper wrapper"><div class="navBreadcrumb wrapper"><div class="navToggle" id="navToggler"><div class="hamburger-menu"><div class="line1"></div><div class="line2"></div><div class="line3"></div></div></div><h2><i>›</i><span>MECHAINE LEARING</span></h2><div class="tocToggler" id="tocToggler"><i class="icon-toc"></i></div></div><div class="navGroups"><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Data Science<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><li class="navListItem"><a class="navItem" href="/blog/docs/DataScience/datascience">datascience Introduction</a></li><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">MECHAINE LEARING</h4><ul><li class="navListItem"><a class="navItem" href="/blog/docs/DataScience/ML/MachineLearningIntroduction">machinelearning</a></li><li class="navListItem"><a class="navItem" href="/blog/docs/DataScience/ML/pca">pca</a></li><li class="navListItem"><a class="navItem" href="/blog/docs/DataScience/ML/t-sne">t-sne</a></li><li class="navListItem"><a class="navItem" href="/blog/docs/DataScience/ML/k-nn">k-nn</a></li><li class="navListItem navListItemActive"><a class="navItem" href="/blog/docs/DataScience/ML/k-dtree">k-dtree</a></li><li class="navListItem"><a class="navItem" href="/blog/docs/DataScience/ML/binarytree">binarytree</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">python</h4><ul><li class="navListItem"><a class="navItem" href="/blog/docs/DataScience/python/numpy">numpy</a></li><li class="navListItem"><a class="navItem" href="/blog/docs/DataScience/python/pandas">pandas</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">sql</h4><ul><li class="navListItem"><a class="navItem" href="/blog/docs/DataScience/sql/joins">joins</a></li><li class="navListItem"><a class="navItem" href="/blog/docs/DataScience/sql/Queries">Queries</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">target</h4><ul><li class="navListItem"><a class="navItem" href="/blog/docs/DataScience/target/target">target</a></li><li class="navListItem"><a class="navItem" href="/blog/docs/DataScience/target/haji">haji</a></li><li class="navListItem"><a class="navItem" href="/blog/docs/DataScience/target/jasmin">jasmin</a></li></ul></div></ul></div></div></section></div><script>
            var coll = document.getElementsByClassName('collapsible');
            var checkActiveCategory = true;
            for (var i = 0; i < coll.length; i++) {
              var links = coll[i].nextElementSibling.getElementsByTagName('*');
              if (checkActiveCategory){
                for (var j = 0; j < links.length; j++) {
                  if (links[j].classList.contains('navListItemActive')){
                    coll[i].nextElementSibling.classList.toggle('hide');
                    coll[i].childNodes[1].classList.toggle('rotate');
                    checkActiveCategory = false;
                    break;
                  }
                }
              }

              coll[i].addEventListener('click', function() {
                var arrow = this.childNodes[1];
                arrow.classList.toggle('rotate');
                var content = this.nextElementSibling;
                content.classList.toggle('hide');
              });
            }

            document.addEventListener('DOMContentLoaded', function() {
              createToggler('#navToggler', '#docsNav', 'docsSliderActive');
              createToggler('#tocToggler', 'body', 'tocActive');

              var headings = document.querySelector('.toc-headings');
              headings && headings.addEventListener('click', function(event) {
                var el = event.target;
                while(el !== headings){
                  if (el.tagName === 'A') {
                    document.body.classList.remove('tocActive');
                    break;
                  } else{
                    el = el.parentNode;
                  }
                }
              }, false);

              function createToggler(togglerSelector, targetSelector, className) {
                var toggler = document.querySelector(togglerSelector);
                var target = document.querySelector(targetSelector);

                if (!toggler) {
                  return;
                }

                toggler.onclick = function(event) {
                  event.preventDefault();

                  target.classList.toggle(className);
                };
              }
            });
        </script></nav></div><div class="container mainContainer docsContainer"><div class="wrapper"><div class="post"><header class="postHeader"><h1 id="__docusaurus" class="postHeaderTitle">k-dtree</h1></header><article><div><span><p>A K-D Tree(also called as K-Dimensional Tree) is a binary search tree where data in each node is a K-Dimensional point in space. ... A non-leaf node in K-D tree divides the space into two parts, called as half-spaces.</p>
<ul>
<li>Invented in 1970s by <strong>Jon Bentley</strong></li>
<li>Name originally meant “3d-trees, 4d-trees, etc”
where k was the # of dimensions</li>
<li>Now, people say “kd-tree of dimension d”</li>
<li><strong>Idea:</strong> Each level of the tree compares against 1</li>
<li>dimension.</li>
<li>Let’s us have only two children at each node (instead of 2d)</li>
</ul>
<p><strong>How to determine if a point will lie in the left subtree or in right subtree?</strong></p>
<p>If the root node is aligned in planeA, then the left subtree will contain all points whose coordinates in that plane are smaller than that of root node. Similarly, the right subtree will contain all points whose coordinates in that plane are greater-equal to that of root node.</p>
<p><strong>Creation of a 2-D Tree:</strong></p>
<p>Consider following points in a 2-D plane:</p>
<p>(3, 6), (17, 15), (13, 15), (6, 12), (9, 1), (2, 7), (10, 19)</p>
<ol>
<li>Insert (3, 6): Since tree is empty, make it the root node.</li>
<li>Insert (17, 15): Compare it with root node point. Since root node is X-aligned, the X-coordinate value will be compared to determine if it lies in the rightsubtree or in the right subtree. This point will be Y-aligned.</li>
<li>Insert (13, 15): X-value of this point is greater than X-value of point in root node. So, this will lie in the right subtree of (3, 6). Again Compare Y-value of this point with the Y-value of point (17, 15) (Why?). Since, they are equal, this point will lie in the right subtree of (17, 15). This point will be X-aligned.</li>
<li>Insert (6, 12): X-value of this point is greater than X-value of point in root node. So, this will lie in the right subtree of (3, 6). Again Compare Y-value of this point with the Y-value of point (17, 15) (Why?). Since, 12 &lt; 15, this point will lie in the left subtree of (17, 15). This point will be X-aligned.</li>
<li>Insert (9, 1):Similarly, this point will lie in the right of (6, 12).</li>
<li>Insert (2, 7):Similarly, this point will lie in the left of (3, 6).</li>
<li>Insert (10, 19): Similarly, this point will lie in the left of (13, 15).</li>
</ol>
<p><img src="/blog/docs/assets/k-d_tree/tree.png" alt="tree"></p>
<p><strong>Find Min in kd-trees</strong></p>
<p>FindMin(d): find the point with the smallest value in
the dth dimension.</p>
<ul>
<li>Recursively traverse the tree</li>
<li>If cutdim(current_node) = d, then the minimum</li>
<li>can’t be in the right subtree, so recurse on just the</li>
<li>left subtree - if no left subtree, then current node is the min for tree</li>
<li>rooted at this node.</li>
<li>If cutdim(current_node) ≠ d, then minimum could</li>
<li>be in either subtree, so recurse on both subtrees. - (unlike in 1-d structures, often have to explore several paths down the tree)</li>
</ul>
<p><strong>FindMin(x-dimension):</strong></p>
<p><img src="/blog/docs/assets/k-d_tree/x.png" alt="FindMin(x-dimension)"></p>
<p><strong>FindMin(Y-dimension):</strong></p>
<p><img src="/blog/docs/assets/k-d_tree/y.png" alt="FindMin(y-dimension)"></p>
<p><strong>FindMin(y-dimension): space searched</strong></p>
<p><img src="/blog/docs/assets/k-d_tree/s.png" alt="FindMin(y-dimension): space searched"></p>
<p><strong>Nearest Neighbor Searching in kd-trees</strong></p>
<p>Nearest Neighbor Queries are very common: given a point Q find the
point P in the data set that is closest to Q.</p>
<p>Doesn’t work: find cell that would contain Q and return the point it
contains.</p>
<ul>
<li>Reason: the nearest point to P in space may be far from P in the
tree:</li>
<li>E.g. NN(52,52):</li>
</ul>
<p><img src="/blog/docs/assets/k-d_tree/eg.png" alt="eg"></p>
<p><strong>kd-Trees Nearest Neighbor</strong></p>
<p><strong>Idea:</strong> traverse the whole tree, BUT make two
modifications to prune to search space</p>
<ol>
<li>Keep variable of closest point C found so far.
Prune subtrees once their bounding boxes say
that they can’t contain any point closer than C</li>
<li>Search the subtrees in order that maximizes the
chance for pruning</li>
</ol>
<p><strong>Nearest Neighbor Facts</strong></p>
<p>Might have to search close to the whole tree in the
worst case. [O(n)]
• In practice, runtime is closer to:</p>
<ul>
<li>O(2d + log n)</li>
<li>log n to find cells “near” the query point</li>
<li>2d to search around cells in that neighborhood</li>
</ul>
<p><strong>Advantages of k-d tree</strong></p>
<blockquote>
<p>k-d trees help in partitioning space just as binary search trees help in partitioning the real line. k-d trees recursively partition a region of space, creating a binary space partition at each level of the tree.</p>
</blockquote>
<p><strong>Disadvantages of K-dtree</strong></p>
<blockquote>
<p>Well, KD-trees are really cool. They're a very intuitive way to think about storing data, and as we saw, they could lead to help us find relevant information way sooner. But there are few issues. KD-trees are not the simplest things to implement.</p>
</blockquote>
</span></div></article></div><div class="docLastUpdate"><em>Last updated on 2020-7-24 by jasmin596</em></div><div class="docs-prevnext"><a class="docs-prev button" href="/blog/docs/DataScience/ML/k-nn"><span class="arrow-prev">← </span><span>k-nn</span></a><a class="docs-next button" href="/blog/docs/DataScience/ML/binarytree"><span>binarytree</span><span class="arrow-next"> →</span></a></div></div></div><nav class="onPageNav"></nav></div><footer class="nav-footer" id="footer"><section class="sitemap"><a href="/blog/" class="nav-home"><img src="/blog/img/I_love_AI.png" alt="Team Data Scientists" width="66" height="58"/></a><div><h5>Docs</h5><a href="/blog/docs/en/doc1.html">Getting Started (or other categories)</a><a href="/blog/docs/en/doc2.html">Guides (or other categories)</a><a href="/blog/docs/en/doc3.html">API Reference (or other categories)</a></div><div><h5>Community</h5><a href="/blog/en/users.html">User Showcase</a><a href="https://stackoverflow.com/questions/tagged/" target="_blank" rel="noreferrer noopener">Stack Overflow</a><a href="https://discordapp.com/">Project Chat</a><a href="https://twitter.com/" target="_blank" rel="noreferrer noopener">Twitter</a></div><div><h5>More</h5><a href="/blog/blog">Blog</a><a href="https://github.com/">GitHub</a><a class="github-button" data-icon="octicon-star" data-count-href="/facebook/docusaurus/stargazers" data-show-count="true" data-count-aria-label="# stargazers on GitHub" aria-label="Star this project on GitHub">Star</a></div></section><a href="https://opensource.facebook.com/" target="_blank" rel="noreferrer noopener" class="fbOpenSource"><img src="/blog/img/oss_logo.png" alt="Facebook Open Source" width="170" height="45"/></a><section class="copyright">Copyright © 2020 DataScience4u</section></footer></div></body></html>